{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Finding Similar Public Transportation Systems to Washington D.C. to Explore Next Steps for Growth"}, {"metadata": {}, "cell_type": "markdown", "source": "### Part of the IBM Data Science Capstone Project"}, {"metadata": {}, "cell_type": "markdown", "source": "### I. Introduction"}, {"metadata": {}, "cell_type": "markdown", "source": "The D.C. Metro is one of the busiest rapid transit systems in the United States, second only to the New York City Subway. As of May 2020, the network includes over 90 stations, six lines and serves thousands in the surrounding areas of Maryland and Virginia. The Washington Metropolitan Area Transit Authority anticipates an average of one million riders daily by 2030. Due to the increase in population and commuters, the WMATA has been focused on extending service, building new stations, and constructing additional lines to alleviate congestion. \n\nThis necessity for growth can be either be an obstacle that hurts a city fiscally and does not meet the demands of the citizens, or it can be an opportunity to expand efficiently, thus decreasing congestion, and easing daily commutes as the population grows. Rather than grow blindly, cities can use the growing arsenal of data analytic techniques to anticipate demand. \n\nTo address this need, I propose a twofold analysis. The first stage involves examining and clustering metro stations in D.C. based on surrounding venues. Leveraging the Foursquare API, we can explore the venue types surrounding each station, thus allowing us to make a model that clusters stations based on their primary usage. In just this first step, city planners can begin to predict the demand of people traveling from this station. For example, if the station is in a largely residential neighborhood, it can be presumed that there is a necessity for transit to commercial and professional neighborhoods. \n\nThe second stage involves looking at a variety of cities with an efficient and expansive transit network and conducting similar clustering analyses. Based on the most popular classifications of metro stations across several cities, we can determine how similar or dissimilar the system in D.C. is to other cities. The similarly clustered cities to D.C. can be explored further by city planners. By looking at more extensive but similar transit systems across the globe, the WMATA can examine how these cities expanded their metro stations. This allows the opportunity for the Washington Metro to learn from predecessors successes and mistakes in the expansion process.  \n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### II. Data"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np \nimport pandas as pd\nimport http.client, urllib.request, urllib.parse, urllib.error, base64\nimport json\n\nprint(\"Import Complete\")", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Import Complete\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "For the first stage, location of each metro station, and the venues surrounding it are needed. \n1. All the metro stations in the D.C. metropolitan area are obtained using the free WMATA API. \n\n   Various information can be found, but for the puposes of this data collection the station list json file was used. There is a substantial amount of extra information in this file that needs to be disguarded to determine station name, latitude and longitude "}, {"metadata": {}, "cell_type": "code", "source": "#Access the WMATA API to get the station information and geographical coordinates\nheaders = {\n    'api_key': 'a6a660fc4acb4c258b9fc0b10da58c72',\n}\n\nconn = http.client.HTTPSConnection('api.wmata.com')\nconn.request(\"GET\", \"/Rail.svc/json/jStations\", \"{body}\", headers)\nresponse = conn.getresponse()\ndata = response.read()\nconn.close()", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Create the DC data frame\ncolumn_names = ['Station', 'Lat', 'Lon']\ndc_metro_df = pd.DataFrame(columns=column_names)", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Turn the byte into a string that can them be made into a json dictionary \nstrdata = data.decode(\"utf-8\")\njson_obj = json.loads(strdata)\n\n#Populate the datatable\ncount = 0\nfor station in json_obj['Stations']:\n    dc_metro_df = dc_metro_df.append({'Station': json_obj['Stations'][count]['Name'],\n                                     'Lat': json_obj['Stations'][count]['Lat'],\n                                     'Lon': json_obj['Stations'][count]['Lon']}, ignore_index = True)\n    count = count + 1\ndc_metro_df.head()", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "                         Station        Lat        Lon\n0                   Metro Center  38.898303 -77.028099\n1                 Farragut North  38.903192 -77.039766\n2                  Dupont Circle  38.909499 -77.043620\n3  Woodley Park-Zoo/Adams Morgan  38.924999 -77.052648\n4                 Cleveland Park  38.934703 -77.058226", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Station</th>\n      <th>Lat</th>\n      <th>Lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Metro Center</td>\n      <td>38.898303</td>\n      <td>-77.028099</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Farragut North</td>\n      <td>38.903192</td>\n      <td>-77.039766</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dupont Circle</td>\n      <td>38.909499</td>\n      <td>-77.043620</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Woodley Park-Zoo/Adams Morgan</td>\n      <td>38.924999</td>\n      <td>-77.052648</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cleveland Park</td>\n      <td>38.934703</td>\n      <td>-77.058226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "For the second stage other metro systems must be selected, and a similar examination must occur.\n1. A list of metro systems around the world with be scraped from [this Wikipedia page.](https://en.wikipedia.org/wiki/List_of_metro_systems)\n\n   The metro stations with the highest annual riderships will be selected for further examination. Using this technique versus hand picking cities with high quality transit systems, allows for the WMATA to see the downfalls of larger systems that do not rank among some of the best. This will allow D.C.'s city planners to learn from similar cities' mistakes while also learning from some of the greatest similar transit systems in the world. \n\n2. A list of each metro station in a city and the geographical coordinates will be obtained either through scraping the Wikipedia page or using a geolocator. \n\n   This is necessary because while the Wikipedia pages do list every metro station in a city's system, they do not always include the coordinates. Therefore, how the coordinates for a station are obtained is dependent on what information can be scraped from the Wikipedia page. For example, the [list of stations in Hong Kong](https://en.wikipedia.org/wiki/List_of_MTR_stations) does not include longitude and latitude. In order to get this, the stations location must be determined using a geolocator. Below is an example of gathering this data for the Lo Wu station in Hong Kong. \n   \n3. Using the Foursquare API, the venues within 500 m will be examined and their type determined. Foursquare will assist in the categorization. \n\nThis concludes the data gathering portion of this project. "}, {"metadata": {}, "cell_type": "code", "source": "address = 'Lo Wu station, HK'\n\ngeolocator = Nominatim(user_agent=\"foursquare_agent\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint(latitude, longitude)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "22.5292045 114.1142734\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}
